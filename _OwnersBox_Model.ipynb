{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mattsmit4/DFScode/blob/main/_OwnersBox_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txU4zrDrPsGq"
      },
      "source": [
        "###Install Packages & Start Timer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_F1eYW1JO8sb",
        "outputId": "0fc9e9c2-7325-4c5a-8df4-efd680d80c40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pulp in /usr/local/lib/python3.10/dist-packages (2.7.0)\n"
          ]
        }
      ],
      "source": [
        "pip install pulp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kCaemr2KPE97"
      },
      "outputs": [],
      "source": [
        "# Importing packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pulp import *\n",
        "import tensorflow as tf\n",
        "from statistics import median\n",
        "from google.colab import files\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import Dropout\n",
        "from keras.constraints import MaxNorm\n",
        "from keras.models import load_model\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import itertools\n",
        "import time\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vcb0ZuVcuRUY"
      },
      "outputs": [],
      "source": [
        "# Record the start time\n",
        "start_time = time.time()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlctj_tNu35c"
      },
      "source": [
        "###Update Rules for Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6ULkHSEu7zJ"
      },
      "outputs": [],
      "source": [
        "# Current week in NFL\n",
        "week = 18\n",
        "# How many model iterations you want\n",
        "iterations = 151\n",
        "# Setting the floor of players to not include\n",
        "floor = 0.2\n",
        "# Setting a maximum for sum of Ownership as a percentage\n",
        "Ownership = 0.84\n",
        "# Set minimums for the projected points\n",
        "NewProjectedPoints_rb_qb_wr = 8.93\n",
        "NewProjectedPoints_te = 9.56"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ocxDF1gxtLd"
      },
      "source": [
        "###Getting Historical Data and Shaping It"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uuxoox1txxRC"
      },
      "outputs": [],
      "source": [
        "# # Bringing in all the data\n",
        "df_2013 = []\n",
        "for i in range(1, 18):\n",
        "    df = locals()[f'df{i}'] = pd.read_csv(fr\"drive/MyDrive/Fantasy-Football-Coding/Fantasy-Data/OwnersBox/Combined/2013/combined-wk{i}.csv\")\n",
        "    df_2013.append(df)\n",
        "df_2013 = pd.concat(df_2013)\n",
        "df_2013 = df_2013.loc[df_2013.Position.isin(['QB', 'RB', 'WR', 'TE'])]\n",
        "\n",
        "df_2014 = []\n",
        "for i in range(1, 18):\n",
        "    df = locals()[f'df{i}'] = pd.read_csv(fr\"drive/MyDrive/Fantasy-Football-Coding/Fantasy-Data/OwnersBox/Combined/2014/combined-wk{i}.csv\")\n",
        "    df_2014.append(df)\n",
        "df_2014 = pd.concat(df_2014)\n",
        "df_2014 = df_2014.loc[df_2014.Position.isin(['QB', 'RB', 'WR', 'TE'])]\n",
        "\n",
        "df_2015 = []\n",
        "for i in range(1, 18):\n",
        "    df = locals()[f'df{i}'] = pd.read_csv(fr\"drive/MyDrive/Fantasy-Football-Coding/Fantasy-Data/OwnersBox/Combined/2015/combined-wk{i}.csv\")\n",
        "    df_2015.append(df)\n",
        "df_2015 = pd.concat(df_2015)\n",
        "df_2015 = df_2015.loc[df_2015.Position.isin(['QB', 'RB', 'WR', 'TE'])]\n",
        "\n",
        "df_2016 = []\n",
        "for i in range(1, 18):\n",
        "    df = locals()[f'df{i}'] = pd.read_csv(fr\"drive/MyDrive/Fantasy-Football-Coding/Fantasy-Data/OwnersBox/Combined/2016/combined-wk{i}.csv\")\n",
        "    df_2016.append(df)\n",
        "df_2016 = pd.concat(df_2016)\n",
        "df_2016 = df_2016.loc[df_2016.Position.isin(['QB', 'RB', 'WR', 'TE'])]\n",
        "\n",
        "df_2017 = []\n",
        "for i in range(1, 18):\n",
        "    df = locals()[f'df{i}'] = pd.read_csv(fr\"drive/MyDrive/Fantasy-Football-Coding/Fantasy-Data/OwnersBox/Combined/2017/combined-wk{i}.csv\")\n",
        "    df_2017.append(df)\n",
        "df_2017 = pd.concat(df_2017)\n",
        "df_2017 = df_2017.loc[df_2017.Position.isin(['QB', 'RB', 'WR', 'TE'])]\n",
        "\n",
        "df_2018 = []\n",
        "for i in range(1, 18):\n",
        "    df = locals()[f'df{i}'] = pd.read_csv(fr\"drive/MyDrive/Fantasy-Football-Coding/Fantasy-Data/OwnersBox/Combined/2018/combined-wk{i}.csv\")\n",
        "    df_2018.append(df)\n",
        "df_2018 = pd.concat(df_2018)\n",
        "df_2018 = df_2018.loc[df_2018.Position.isin(['QB', 'RB', 'WR', 'TE'])]\n",
        "\n",
        "df_2019 = []\n",
        "for i in range(1, 18):\n",
        "    df = locals()[f'df{i}'] = pd.read_csv(fr\"drive/MyDrive/Fantasy-Football-Coding/Fantasy-Data/OwnersBox/Combined/2019/combined-wk{i}.csv\")\n",
        "    df_2019.append(df)\n",
        "df_2019 = pd.concat(df_2019)\n",
        "df_2019 = df_2019.loc[df_2019.Position.isin(['QB', 'RB', 'WR', 'TE'])]\n",
        "\n",
        "df_2020 = []\n",
        "for i in range(1, 18):\n",
        "    df = locals()[f'df{i}'] = pd.read_csv(fr\"drive/MyDrive/Fantasy-Football-Coding/Fantasy-Data/OwnersBox/Combined/2020/combined-wk{i}.csv\")\n",
        "    df_2020.append(df)\n",
        "df_2020 = pd.concat(df_2020)\n",
        "df_2020 = df_2020.loc[df_2020.Position.isin(['QB', 'RB', 'WR', 'TE'])]\n",
        "\n",
        "df_2021 = []\n",
        "for i in range(1, 19):\n",
        "    df = locals()[f'df{i}'] = pd.read_csv(fr\"drive/MyDrive/Fantasy-Football-Coding/Fantasy-Data/OwnersBox/Combined/2021/combined-wk{i}.csv\")\n",
        "    df_2021.append(df)\n",
        "df_2021 = pd.concat(df_2021)\n",
        "df_2021 = df_2021.loc[df_2021.Position.isin(['QB', 'RB', 'WR', 'TE'])]\n",
        "\n",
        "df_2022 = []\n",
        "for i in range(1, 19):\n",
        "    df = locals()[f'df{i}'] = pd.read_csv(fr\"drive/MyDrive/Fantasy-Football-Coding/Fantasy-Data/OwnersBox/Combined/2022/combined-wk{i}.csv\")\n",
        "    df_2022.append(df)\n",
        "df_2022 = pd.concat(df_2022)\n",
        "df_2022 = df_2022.loc[df_2022.Position.isin(['QB', 'RB', 'WR', 'TE'])]\n",
        "\n",
        "df_2023 = []\n",
        "for i in range(1, week):\n",
        "    df = locals()[f'df{i}'] = pd.read_csv(fr\"drive/MyDrive/Fantasy-Football-Coding/Fantasy-Data/OwnersBox/Combined/2023/combined-wk{i}.csv\")\n",
        "    df_2023.append(df)\n",
        "df_2023 = pd.concat(df_2023)\n",
        "df_2023 = df_2023.loc[df_2023.Position.isin(['QB', 'RB', 'WR', 'TE'])]\n",
        "\n",
        "# Combining all the yearly data frames into one\n",
        "df = pd.concat([df_2013, df_2014, df_2015, df_2016, df_2017, df_2018, df_2019, df_2020, df_2021, df_2022, df_2023])\n",
        "df.shape\n",
        "\n",
        "# Fill NaN values with 0.0\n",
        "df = df.fillna(0.0)\n",
        "# Resetting the index\n",
        "df = df.reset_index(drop=True)\n",
        "\n",
        "# Lists to Define the positions you want to filter for each group\n",
        "positions_rb_qb_wr = ['RB', 'QB', 'WR']\n",
        "positions_te = ['TE']\n",
        "\n",
        "# This keeps all the data where the Projected Points are greather than or equal to what the variable is\n",
        "# Create a condition based on Tight Ends\n",
        "is_te = df['Position'] == 'TE'\n",
        "# Filter the DataFrame based on the conditions\n",
        "df.loc[is_te, 'Keep'] = (df['NewProjectedPoints'] >= NewProjectedPoints_te)\n",
        "df.loc[~is_te, 'Keep'] = (df['NewProjectedPoints'] >= NewProjectedPoints_rb_qb_wr)\n",
        "\n",
        "# Drop rows where 'Keep' is False\n",
        "df = df[df['Keep']]\n",
        "\n",
        "# Getting the Home and Away data from Categorical to Numbers\n",
        "dummies = pd.get_dummies(df.HomeAway)\n",
        "\n",
        "# Concatenate the dummy dataframe and the main one\n",
        "df = pd.concat([df, dummies], axis='columns')\n",
        "# Drop the 'Keep' column\n",
        "df = df.drop(columns='Keep')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yEy4d8O0QzE"
      },
      "source": [
        "###Train & Test Split and Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "X-bvQI9IVntq",
        "outputId": "20bf8d49-134b-4414-aa35-73c321929972"
      },
      "outputs": [],
      "source": [
        "# Splitting the data into features and the label\n",
        "X = df[['NewProjectedPoints', 'Home', 'OverUnder', 'Trend']].values\n",
        "y = df[['NewActualPoints']].values\n",
        "\n",
        "# Define hyperparamters to keep each iteration the same seed\n",
        "random_seeds = []\n",
        "for rs in range(1, iterations):\n",
        "  random_seeds.append(rs)\n",
        "\n",
        "# Lists to store performance metrics\n",
        "val_loss_scores = []\n",
        "best_model_paths = []\n",
        "mse_loss_scores = []\n",
        "\n",
        "# Split the data into training and testing and saving the best loss rate for each iteration of the model\n",
        "for seed in random_seeds:\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed, shuffle=True)\n",
        "\n",
        "  # Scale both the train and test, otherwise the model will fail\n",
        "  # Standardize features by removing the mean and scaling to unit variance\n",
        "  scaler = StandardScaler()\n",
        "  scaler.fit(X_train)\n",
        "\n",
        "  # The new variables are being scaled based on the standardizing features that happened in X_train\n",
        "  X_train_scaled = scaler.transform(X_train)\n",
        "  X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "  # Define the model\n",
        "  model = Sequential()\n",
        "  # First hidden layer number of neurons and number of inputs, with the type of activation\n",
        "  model.add(Dense(6, input_shape=(4,), activation='relu'))\n",
        "  # Second Hidden Layer\n",
        "  model.add(Dense(6, activation='relu'))\n",
        "  # Output layer\n",
        "  model.add(Dense(1, activation='linear'))\n",
        "\n",
        "\n",
        "  # Compile the model (which defines the loss function, the optimizer, and the metrics)\n",
        "  model.compile(tf.keras.optimizers.Adam(learning_rate=0.001), loss='mean_squared_error')\n",
        "  model.summary\n",
        "\n",
        "  # Save the best model\n",
        "  checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True, mode='min', verbose=1)\n",
        "\n",
        "  # Fitting the model\n",
        "  history = model.fit(X_train_scaled, y_train, validation_split=0.2, epochs=11, callbacks=[checkpoint])\n",
        "\n",
        "  # Saving the best model validation losses\n",
        "  best_val_loss = min(history.history['val_loss'])\n",
        "  val_loss_scores.append(best_val_loss)\n",
        "  best_model = load_model('best_model.h5')\n",
        "  best_model_paths.append(best_model)\n",
        "\n",
        "\n",
        "  # Using the best model on the Test data now\n",
        "  mse_neural = best_model.evaluate(X_test_scaled, y_test)\n",
        "  print('')\n",
        "  print(\"Iteration:\", seed )\n",
        "  print(f\"Mean Squared Error: {mse_neural:.3f}\")\n",
        "  #print(\"Mean Squared Error from neural network: \", mse_neural)\n",
        "  print(f\"Best Validation Loss: {best_val_loss:.3f}\")\n",
        "  #print(\"Best Validation Loss: \", best_val_loss)\n",
        "  print('')\n",
        "  mse_loss_scores.append(mse_neural)\n",
        "\n",
        "  # Plot the training and validation loss at each epoch\n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "  epochs = range(1, len(loss) + 1)\n",
        "  # Does a line\n",
        "  plt.plot(epochs, loss, 'y', label='Training Loss')\n",
        "  # Does a dot\n",
        "  #plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "  plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
        "  plt.title(\"Training and Validation Loss\")\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "  print('')\n",
        "  print('---------------------------------------------------------------------------')\n",
        "  print('')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amK9NR2R8RJz"
      },
      "source": [
        "###Getting Top Ownership Lineup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gn5Kl1s8Usl",
        "outputId": "e26fcd13-9438-4f62-d670-68cf33e1a865"
      },
      "outputs": [],
      "source": [
        "# Bring in the Data\n",
        "df_ownership = pd.read_csv(f\"drive/MyDrive/Fantasy-Football-Coding/Fantasy-Data/OwnersBox/_Current/Current-wk{week}.csv\")\n",
        "# Fill NaN values with 0.0\n",
        "df_ownership = df_ownership.fillna(0.0)\n",
        "df_ownership = df_ownership[['Name', 'Position', 'Salary', 'Ownership']]\n",
        "df_ownership = df_ownership[df_ownership['Salary'] != 0]\n",
        "\n",
        "# Group players by position\n",
        "availables = df_ownership.groupby([\"Name\", \"Position\", \"Salary\",'Ownership']).size().reset_index(name='Count')\n",
        "\n",
        "# Define empty dictionaries to track the metrics for the lineup optimizer\n",
        "salaries = {}\n",
        "players = {}\n",
        "ownerships = {}\n",
        "lineups_dict = {}\n",
        "\n",
        "# Group players by position and create dictionaries for key player attributes\n",
        "for position in availables.Position.unique():\n",
        "    available_for_position = availables[availables.Position == position]\n",
        "\n",
        "    players[position] = list(available_for_position['Name'])\n",
        "    salaries[position] = dict(zip(available_for_position['Name'], available_for_position['Salary']))\n",
        "    ownerships[position] = dict(zip(available_for_position['Name'], available_for_position['Ownership']))\n",
        "\n",
        "# Define lineup constraints and variables\n",
        "positions_available = {\n",
        "    \"QB\": 2,\n",
        "    \"RB\": 2,\n",
        "    \"WR\": 2,\n",
        "    \"TE\": 1,\n",
        "    \"FLEX\": 2\n",
        "}\n",
        "\n",
        "flexible_positions = (\"RB\", \"WR\", \"TE\")\n",
        "salary_cap = 50000\n",
        "variables = {position: LpVariable.dict(position, players[position], cat=\"Binary\") for position in players}\n",
        "\n",
        "# Create lineups\n",
        "for lineup in range(1, 2):\n",
        "    prob = LpProblem(\"Fantasy\", LpMaximize)\n",
        "\n",
        "    rewards = []\n",
        "    costs = []\n",
        "    number_of_selected_players = []\n",
        "\n",
        "\n",
        "    for position, players in variables.items():\n",
        "        for player, player_selected in players.items():\n",
        "            costs += salaries[position][player] * player_selected\n",
        "            rewards += ownerships[position][player] * player_selected  # Use ownership instead of points\n",
        "            number_of_selected_players += player_selected\n",
        "\n",
        "\n",
        "        if position not in flexible_positions:\n",
        "            prob += lpSum(players.values()) == positions_available[position]\n",
        "        else:\n",
        "            prob += lpSum(players.values()) >= positions_available[position]\n",
        "            prob += lpSum(players.values()) <= positions_available[position] + positions_available[\"FLEX\"]\n",
        "\n",
        "    prob += lpSum(number_of_selected_players) == sum(positions_available.values())\n",
        "    prob += lpSum(rewards)\n",
        "    prob += lpSum(costs) <= salary_cap\n",
        "\n",
        "\n",
        "    num = 0.001\n",
        "    if not lineup == 1:\n",
        "        prob += (lpSum(rewards) <= total_ownership - num)  # Update to use total ownership\n",
        "    prob.solve()\n",
        "\n",
        "    ownership = str(prob.objective)  # Use ownership instead of total score\n",
        "\n",
        "    lineupList = []\n",
        "\n",
        "    for v in prob.variables():\n",
        "        ownership = ownership.replace(v.name, str(v.varValue))\n",
        "        if v.varValue != 0:\n",
        "            lineupList.append(v.name)\n",
        "\n",
        "    total_ownership = eval(ownership)  # Update to use ownership\n",
        "    lineupList.append(total_ownership)\n",
        "\n",
        "    lineups_dict.update({lineup: lineupList})\n",
        "\n",
        "# Create a DataFrame from the lineup data\n",
        "df = pd.DataFrame(lineups_dict).T\n",
        "newcols = ['QB', 'SUPER', 'RB1', 'RB2', 'FLEXorTE', 'TEorFLEX', 'FLEX2', 'WR1', 'WR2', 'Ownership']  # Update column name\n",
        "\n",
        "df.columns = newcols\n",
        "\n",
        "removeKeys = ['QB_', 'RB_', 'TE_', 'WR_']\n",
        "\n",
        "for pos in newcols:\n",
        "    for removeKey in removeKeys:\n",
        "        df[pos] = df[pos].apply(str).str.replace(removeKey, \"\")\n",
        "    df[pos] = df[pos].apply(str).str.replace(\"_\", \" \")\n",
        "\n",
        "df['Ownership'] = df['Ownership'].astype(float).round(2).apply(lambda x: f'{x:.2f}')  # Format ownership as desired\n",
        "\n",
        "first_row = df.head(1)\n",
        "# Extract the 'Ownership' column from the first row\n",
        "max_ownership = float(first_row['Ownership'].values[0])\n",
        "new_ownership = max_ownership * Ownership\n",
        "\n",
        "print(first_row)\n",
        "print(\"\")\n",
        "print(new_ownership)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kiu5x06d_-5f"
      },
      "source": [
        "###Bringing in Upcoming Weeks Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iW9eUicLACJk"
      },
      "outputs": [],
      "source": [
        "# Bring in the data\n",
        "df_test = pd.read_csv(f\"drive/MyDrive/Fantasy-Football-Coding/Fantasy-Data/OwnersBox/_Current/Current-wk{week}.csv\")\n",
        "\n",
        "# Fill NaN values with 0.0\n",
        "df_test = df_test.fillna(0.0)\n",
        "# Get rid of low floor players\n",
        "df_test = df_test[df_test['Floor'] >= floor]\n",
        "\n",
        "\n",
        "# Create a condition based on 'Position'\n",
        "is_te_test = df_test['Position'] == 'TE'\n",
        "\n",
        "# Filter the DataFrame based on the condition\n",
        "df_test.loc[is_te_test, 'Keep'] = (df_test['NewProjectedPoints'] >= NewProjectedPoints_te)\n",
        "df_test.loc[~is_te_test, 'Keep'] = (df_test['NewProjectedPoints'] >= NewProjectedPoints_rb_qb_wr)\n",
        "\n",
        "# Drop rows where 'Keep' is False\n",
        "df_test = df_test[df_test['Keep']]\n",
        "\n",
        "# Getting the Home and Away data from Categorical to Numbers\n",
        "dummies_test = pd.get_dummies(df_test.HomeAway)\n",
        "\n",
        "# Concatenate the dummy dataframe and the main one\n",
        "df_test = pd.concat([df_test, dummies_test], axis='columns')\n",
        "\n",
        "# Drop the 'Keep' column\n",
        "df_test = df_test.drop(columns='Keep')\n",
        "\n",
        "# Splitting the data into features and picking what features I want to include\n",
        "X = df_test[['NewProjectedPoints', 'Home', 'OverUnder', 'Trend']].values\n",
        "\n",
        "# Standardize the features so it matches the type of numbers that the model was trained on\n",
        "scaler.fit(X)\n",
        "\n",
        "# The new variables are being scaled based on the standardizing features that happened in X_train\n",
        "X_scaled = scaler.transform(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vgez0WCP3FVv"
      },
      "source": [
        "###Setting the Constraints and Printing the Lineups"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9T85qzF3iXR",
        "outputId": "f3b642d5-7444-45dc-e276-c4217fb8bb73"
      },
      "outputs": [],
      "source": [
        "# To set the minimum so that any errors in the training process don't get into results\n",
        "std_dev = np.std(val_loss_scores)\n",
        "loss_threshold = median(val_loss_scores) + std_dev + 3\n",
        "\n",
        "df_list = []\n",
        "\n",
        "for index, value in enumerate(val_loss_scores):\n",
        "  if value <= loss_threshold:\n",
        "    each_model = best_model_paths[index]\n",
        "    formatted_value = \"{:.2f}\".format(value)\n",
        "    print(\"Index:\", index, \"Value:\", formatted_value)\n",
        "    y_points = each_model.predict(X_scaled)\n",
        "\n",
        "    # Add the new column into the dataframe\n",
        "    df_test = df_test.assign(NNProjectedPoints=y_points)\n",
        "\n",
        "    # Changing the NewProjectedPoints column to round to 3 decimal places\n",
        "    decimals = 3\n",
        "    df_test['NNProjectedPoints'] = df_test['NNProjectedPoints'].round(decimals)\n",
        "\n",
        "    # Creating a DataFrame with just the listed columns\n",
        "    df_test = df_test[['Name', 'Position', 'NNProjectedPoints', 'Salary', 'Team', 'Ownership', 'Trend']]\n",
        "    # Keeping the rows that have a salary greater than 1\n",
        "    df_test = df_test[df_test['Salary'] > 1]\n",
        "\n",
        "    # This is regrouping the dataframe so the players are grouped by Position\n",
        "    availables = df_test.groupby([\"Position\", \"Name\", \"NNProjectedPoints\", \"Salary\", 'Team', 'Ownership', 'Trend']).size().reset_index(name='Count')\n",
        "\n",
        "    # Define empty dictionaries to track the metrics for the lineup optimizer\n",
        "    salaries = {}\n",
        "    points = {}\n",
        "    players = {}\n",
        "    teams = {}\n",
        "    ownerships = {}\n",
        "    trends = {}\n",
        "    lineups_dict = {}\n",
        "\n",
        "\n",
        "    # Group players by position\n",
        "    for position in availables.Position.unique():\n",
        "        available_for_position = availables[availables.Position == position]\n",
        "\n",
        "        players[position] = list(available_for_position['Name'])\n",
        "        salaries[position] = dict(zip(available_for_position['Name'], available_for_position['Salary']))\n",
        "        points[position] = dict(zip(available_for_position['Name'], available_for_position['NNProjectedPoints']))\n",
        "        teams[position] = dict(zip(available_for_position['Name'], available_for_position['Team']))\n",
        "        ownerships[position] = dict(zip(available_for_position['Name'], available_for_position['Ownership']))\n",
        "        trends[position] = dict(zip(available_for_position['Name'], available_for_position['Trend']))\n",
        "\n",
        "    # This defines another dictionary that has the positions and lineup.\n",
        "    positions_available = {\n",
        "        \"QB\": 2,\n",
        "        \"RB\": 2,\n",
        "        \"WR\": 2,\n",
        "        \"TE\": 1,\n",
        "        \"FLEX\": 2\n",
        "    }\n",
        "\n",
        "    flexible_positions = (\"RB\", \"WR\", \"TE\")\n",
        "    salary_cap = 50000\n",
        "\n",
        "    # Create variables to track player selections\n",
        "    variables = {position: LpVariable.dict(position, players[position], cat=\"Binary\")\n",
        "                  for position in players}\n",
        "\n",
        "    # Extract unique team names from the DataFrame\n",
        "    all_teams = df_test[\"Team\"].unique().tolist()\n",
        "\n",
        "    # Create a dictionary to track the number of players selected from each team\n",
        "    team_selection_count = {team: lpSum(variables[position][(player, team)] for position in players for player in players[position] if player[1] == team)\n",
        "                          for team in all_teams}\n",
        "\n",
        "    # Iterate to create multiple lineups\n",
        "    for lineup in range(1, 11):\n",
        "      #The \"problem\" is we want to have the maximum salary for each lineup.\n",
        "      prob = LpProblem(\"Fantasy\", LpMaximize)\n",
        "\n",
        "      # Creating an empty list to track\n",
        "      rewards = []\n",
        "      costs = []\n",
        "      number_of_selected_players = []\n",
        "      ownership_projections = []\n",
        "      trends_ = []\n",
        "\n",
        "      # Create a dictionary to track the team of each selected player\n",
        "      selected_team = {}\n",
        "\n",
        "\n",
        "      for position, players in variables.items():\n",
        "        for player, player_selected in players.items():\n",
        "          # If this player is selected, he will add salaries and points\n",
        "            costs += salaries[position][player] * player_selected\n",
        "            rewards += points[position][player] * player_selected\n",
        "            number_of_selected_players += player_selected\n",
        "            ownership_projections += ownerships[position][player] * player_selected\n",
        "            trends_ += trends[position][player] * player_selected\n",
        "\n",
        "        if position not in flexible_positions:\n",
        "            prob += lpSum(players.values()) == positions_available[position]  # Filling in the QB\n",
        "        else:\n",
        "              prob += lpSum(players.values()) >= positions_available[position]  # Filling in the RB, WR, TE\n",
        "              prob += lpSum(players.values()) <= positions_available[position] + positions_available[\"FLEX\"]  # Filling in the FLEX\n",
        "\n",
        "\n",
        "      # Create the same positional player cannot be on the same team\n",
        "      for position, players in variables.items():\n",
        "        for player, player_selected in players.items():\n",
        "           if player_selected == 1:\n",
        "              team = teams[position][player]\n",
        "              players_from_same_team = [p for p in players if teams[position][p] == team]\n",
        "              prob += lpSum(variables[position][p] for p in players_from_same_team) <= 1\n",
        "\n",
        "\n",
        "      # This sums up the points and sums up the salary while making sure the lineup salary is less than or equal to the 50,000\n",
        "      # In total, we need exactly `positions_available` players\n",
        "      prob += lpSum(number_of_selected_players) == sum(positions_available.values())\n",
        "      prob += lpSum(rewards)\n",
        "      prob += lpSum(costs) <= salary_cap\n",
        "      prob += lpSum(ownership_projections) <= new_ownership\n",
        "\n",
        "\n",
        "      num = 0.001\n",
        "      # If it's not the first lineup\n",
        "      if not lineup == 1:\n",
        "        # Make sure the rewards (points) is less than or equal too the total of the previous lineup, minus 0.01\n",
        "        # That is too ensure you don't get the same lineup each time becasue the max points of the lineup caps out\n",
        "        # at just below the previous total projections. This ensures varied lineups, and then solve\n",
        "        prob += (lpSum(rewards) <= total_score - num)\n",
        "      prob.solve()\n",
        "\n",
        "      # Getting the strings for the lineup and the constraints (which is same position) when starting the new lineup.\n",
        "      score = str(prob.objective)\n",
        "      constraints = [str(const) for const in prob.constraints.values()]\n",
        "\n",
        "      # Creating an empty list for storing the lineup\n",
        "      lineupList = []\n",
        "\n",
        "      # This will create a list of every player in the dataset with a variable of 1 or 0, depending the player\n",
        "      # has been chosen for the lineup. This loops through the list to fill in if the player has been chosen or not.\n",
        "      for v in prob.variables():\n",
        "          score = score.replace(v.name, str(v.varValue))\n",
        "          if v.varValue != 0:\n",
        "            lineupList.append(v.name)\n",
        "\n",
        "\n",
        "      # # Finally we just have to save the total_score variable for the lineup.\n",
        "      total_score = eval(score)\n",
        "      lineupList.append(total_score)\n",
        "\n",
        "      # Calculate and display the sum of ownership percentages for the selected players\n",
        "      total_ownership = sum(\n",
        "          ownerships[position][player] * v.varValue\n",
        "          for position, players in variables.items()\n",
        "          for player, v in players.items()\n",
        "          if v.varValue == 1)\n",
        "\n",
        "      total_trends = sum(\n",
        "          trends[position][player] * v.varValue\n",
        "          for position, players in variables.items()\n",
        "          for player, v in players.items()\n",
        "          if v.varValue == 1\n",
        "\n",
        "      )\n",
        "\n",
        "      # Add the total ownership to the lineupList\n",
        "      lineupList.append(total_ownership)\n",
        "      lineupList.append(total_trends)\n",
        "\n",
        "\n",
        "      # # Storing all of the lineups in a dictionary\n",
        "      lineups_dict.update({lineup: lineupList})\n",
        "\n",
        "    # Turning the dictionary into a DataFrame and Transpose\n",
        "    df = pd.DataFrame(lineups_dict).T\n",
        "\n",
        "    # Creating a list for what the rename the column names\n",
        "    newcols = ['QB', 'SUPER', 'RB1', 'RB2', 'FLEXorTE', 'TEorFLEX', 'FLEX2', 'WR1', 'WR2', 'Total_Score', 'Ownership %', 'Trend']\n",
        "\n",
        "    # Adding that column name list into the DataFrame\n",
        "    df.columns = newcols\n",
        "\n",
        "    # Creating a list of what values to remove in each particular cell\n",
        "    removeKeys = ['QB_', 'RB_', 'TE_', 'WR_']\n",
        "    # For each position in each column, when the player has the position and _ in front of it, remove that and replace it with nothing\n",
        "    for pos in newcols:\n",
        "      for removeKey in removeKeys:\n",
        "          df[pos] = df[pos].apply(str).str.replace(removeKey,\"\")\n",
        "      df[pos] = df[pos].apply(str).str.replace(\"_\", \" \")\n",
        "\n",
        "    # Changing the columns to round to 2 decimal places\n",
        "    df['Total_Score'] = df['Total_Score'].astype(float).round(2).apply(lambda x: f'{x:.2f}')\n",
        "    df['Ownership %'] = df['Ownership %'].astype(float).round(2).apply(lambda x: f'{x:.2f}')\n",
        "\n",
        "    # Showing what the top lineups are\n",
        "    df_list.append(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SACnX_5N7NDg"
      },
      "source": [
        "###End Timer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQMVPMSqYZV9",
        "outputId": "7ab9c13a-83a5-497d-a11c-a66a47a4872c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total time taken: 66 minutes\n"
          ]
        }
      ],
      "source": [
        "# Record the end time\n",
        "end_time = time.time()\n",
        "# Calculate the elapsed time in seconds\n",
        "elapsed_time = end_time - start_time\n",
        "# Convert elapsed time to minutes\n",
        "elapsed_minutes = elapsed_time / 60\n",
        "print(f\"Total time taken: {elapsed_minutes:.0f} minutes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qu8MJias7Qp2"
      },
      "source": [
        "###Viewing the Top Lineups"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTSs5vV1YRt0",
        "outputId": "def5e9ee-5d20-4af3-b4ca-24780e78b8fb"
      },
      "outputs": [],
      "source": [
        "# Create the df from the appended list\n",
        "result_df = pd.concat(df_list, ignore_index=True)\n",
        "\n",
        "# Group the lineups based on 'Ownership' and 'Trend' and add a 'Group_Count' column\n",
        "result_df['Count'] = result_df.groupby(['Ownership %', 'Trend']).cumcount() + 1\n",
        "\n",
        "# Rename the 'Group_Count' column to 'Group_Count / Iterations'\n",
        "result_df = result_df.rename(columns={'Count': f'Count / {iterations -1}'})\n",
        "\n",
        "# Sort the DataFrame by 'Group_Count' in descending order\n",
        "result_df = result_df.sort_values(by=f'Count / {iterations -1}', ascending=False).reset_index(drop=True)\n",
        "\n",
        "# Remove duplicates based on 'Ownership' and 'Trend'\n",
        "result_df = result_df.drop_duplicates(subset=['Ownership %', 'Trend'], keep='first')\n",
        "\n",
        "# Convert 'Trend' column to numeric type\n",
        "result_df['Trend'] = pd.to_numeric(result_df['Trend'], errors='coerce')\n",
        "\n",
        "# Calculate adjusted 'Trend' values\n",
        "result_df['Trend'] = round(result_df['Trend'] / 9, 2)\n",
        "\n",
        "# Convert 'Trend' column to numeric type\n",
        "result_df['Ownership %'] = pd.to_numeric(result_df['Ownership %'], errors='coerce')\n",
        "\n",
        "# Getting the Ownership as a % of max\n",
        "result_df['Ownership %'] = round(result_df['Ownership %'] / float(max_ownership), 2)\n",
        "\n",
        "# Reset the index of the DataFrame\n",
        "result_df = result_df.reset_index(drop=True)\n",
        "\n",
        "# Start the index at 1 instead of 0\n",
        "result_df.index = result_df.index + 1\n",
        "\n",
        "result_df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NRJdH9PH2S4d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPsbAgpGyE78/zAmZ8owKaD",
      "collapsed_sections": [
        "txU4zrDrPsGq",
        "xlctj_tNu35c",
        "1ocxDF1gxtLd",
        "amK9NR2R8RJz",
        "Kiu5x06d_-5f",
        "Vgez0WCP3FVv"
      ],
      "include_colab_link": true,
      "mount_file_id": "1Ak8L6YhyARzRBzi5P25hugtVMgY40GEL",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
